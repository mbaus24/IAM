{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_RSbkUJBWRe"
   },
   "source": [
    "Ce TP est en deux parties\n",
    "\n",
    "\n",
    "*   La première consiste à programmer quelques méthodes de classification multilabel\n",
    "*   La seconde consiste à benchmarker des méthodes de classific aiton multilael sur un jeu de données, en utiisant un package dédié à la classification multilabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dAAmcdwBNgE"
   },
   "source": [
    "# 1. Programmation de méthodes de classification multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUno0SnXBqAF"
   },
   "source": [
    "## Lien avec le drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QotQcIA_y6Ji"
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6jHDS-hiGe1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1ce1fulqzEA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sa3oO1-OplL9"
   },
   "source": [
    "## Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FSYvge6EplL-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, make_scorer, f1_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import clone\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdLjn4pEplL-"
   },
   "source": [
    "## 0. Load the Yeast Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "error",
     "timestamp": 1734091299361,
     "user": {
      "displayName": "Thierry Artieres",
      "userId": "02018666546133225436"
     },
     "user_tz": -60
    },
    "id": "MWhl_RjoplL_",
    "outputId": "9e7d6857-f681-488a-c65f-fee7986391ea"
   },
   "outputs": [],
   "source": [
    "yeast = pd.read_csv('yeast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "error",
     "timestamp": 1734091299361,
     "user": {
      "displayName": "Thierry Artieres",
      "userId": "02018666546133225436"
     },
     "user_tz": -60
    },
    "id": "kqg3rUvfplMA",
    "outputId": "9aa82d83-a579-4939-92b9-4c6d7bbae26c"
   },
   "outputs": [],
   "source": [
    "X = yeast.iloc[:, 0:-14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1734091299361,
     "user": {
      "displayName": "Thierry Artieres",
      "userId": "02018666546133225436"
     },
     "user_tz": -60
    },
    "id": "0wiMG9EpplMA"
   },
   "outputs": [],
   "source": [
    "y = yeast.iloc[:,-14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1734091299361,
     "user": {
      "displayName": "Thierry Artieres",
      "userId": "02018666546133225436"
     },
     "user_tz": -60
    },
    "id": "1jPm5ioKplMB"
   },
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0cKEagSB-P0"
   },
   "source": [
    "## Définition de métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ri9KAcPnB9f3"
   },
   "outputs": [],
   "source": [
    "# Que calculent les métriques suivantes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "c1VQlrkqplMB"
   },
   "outputs": [],
   "source": [
    "# Custom accuracy score\n",
    "\n",
    "def get_accuracy_score(y_pred,y_test):\n",
    "\n",
    "    if 'numpy' not in str(type(y_pred)):\n",
    "        y_pred = y_pred.to_numpy()\n",
    "\n",
    "    if 'numpy' not in str(type(y_test)):\n",
    "        y_test = y_test.to_numpy()\n",
    "\n",
    "\n",
    "    assert(y_test.shape == y_pred.shape)\n",
    "\n",
    "    if y_pred.shape[1] <= 5: #For a smaller number of labels, a ratio of half the labels being correct is good enough\n",
    "        ratio = 0.5\n",
    "    else:\n",
    "        ratio = 0.7 #For a number of labels, at least 70% of the predicted labels must be correct\n",
    "\n",
    "    acc_rows = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        acc_rows.append(np.count_nonzero(y_test[i]==y_pred[i]))\n",
    "\n",
    "    acc_rows = [1 if x/y_pred.shape[1] >= ratio else 0 for x in acc_rows] #1 if ratio of match in a row is greater than ratio, else 0\n",
    "    return sum(acc_rows)/len(acc_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "eCUkfSLINMb8"
   },
   "outputs": [],
   "source": [
    "### Distance de Hamming\n",
    "\n",
    "def HammingDistance_score(y_pred,y_test):\n",
    "\n",
    "    if 'numpy' not in str(type(y_pred)):\n",
    "        y_pred = y_pred.to_numpy()\n",
    "\n",
    "    if 'numpy' not in str(type(y_test)):\n",
    "        y_test = y_test.to_numpy()\n",
    "\n",
    "    acc_rows = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "      acc_rows.append(np.count_nonzero(y_test[i]!=y_pred[i]))\n",
    "\n",
    "    return sum(acc_rows)/len(acc_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvgCmT3tplMB"
   },
   "source": [
    "## 1. Implement the Binary Relevance Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMxpjLOOCaZH"
   },
   "source": [
    "Implémentez la classe BinaryRelevanceClassifier suivante qui prend en paramètre un estimateur et va l'utiliser sur chacun des labels qe ce soit en apprentissage ou en inférence.\n",
    "* Vous stockerez les modèles dans une liste *model_list*\n",
    "* Il est inutile d'implémenter la méthode *predict_proba*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3zHCtTEjplMB"
   },
   "outputs": [],
   "source": [
    "class BinaryRelevanceClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, base_model=LogisticRegression()):\n",
    "        self.base_model = base_model #base model - by default logistic regression\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model_list_ = []\n",
    "        self.y_columns = y.columns\n",
    "        for column in y.columns:\n",
    "            y_column = y[column]\n",
    "            model = clone(self.base_model)\n",
    "            model.fit(X, y_column)\n",
    "            self.model_list_.append(model)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self,X):\n",
    "        y_pred = pd.DataFrame()\n",
    "        for i, model in enumerate(self.model_list_):\n",
    "            y_pred[self.y_columns[i]] = model.predict(X)\n",
    "        \n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "        ...\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A90J_6XPDggQ"
   },
   "source": [
    "Le code de la cellule suivante doit fonctionner si la classe BinaryRelevance ci-dessus est ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "DUcHcOO3plMC"
   },
   "outputs": [],
   "source": [
    "binclf = BinaryRelevanceClassifier(base_model=SVC(C=0.01, kernel='sigmoid', probability=True))\n",
    "binclf.fit(X_train,y_train)\n",
    "y_pred = binclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e6EGWlYplMC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8553719008264463"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hamming Distance : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.2355371900826446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1 score : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.12049772347410956"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Accuracy : ',get_accuracy_score(y_test,y_pred), 'Hamming Distance : ', HammingDistance_score(y_test,y_pred) )\n",
    "display('F1 score : ',f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUcIhXAAwt-R"
   },
   "source": [
    "# 2. Implement the label set method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zusBhH7Kd_Ku"
   },
   "source": [
    "## Construction des labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ID8VWrUB5P8-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Class1  Class2  Class3  Class4  Class5  Class6  Class7  Class8  Class9  \\\n",
      "0          0       0       0       0       0       0       1       1       0   \n",
      "1          0       0       1       1       0       0       0       0       0   \n",
      "2          0       1       1       0       0       0       0       0       0   \n",
      "3          0       0       1       1       0       0       0       0       0   \n",
      "4          0       0       1       1       1       1       0       0       0   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "2412       0       1       1       0       0       0       0       0       0   \n",
      "2413       1       1       0       0       0       0       0       0       0   \n",
      "2414       0       0       0       0       0       1       1       1       0   \n",
      "2415       0       0       0       0       0       0       0       0       0   \n",
      "2416       0       1       1       0       0       0       0       0       0   \n",
      "\n",
      "      Class10  Class11  Class12  Class13  Class14  \n",
      "0           0        0        1        1        0  \n",
      "1           0        0        0        0        0  \n",
      "2           0        0        1        1        0  \n",
      "3           0        0        0        0        0  \n",
      "4           0        0        0        0        0  \n",
      "...       ...      ...      ...      ...      ...  \n",
      "2412        0        0        0        0        0  \n",
      "2413        0        0        1        1        0  \n",
      "2414        0        0        1        1        0  \n",
      "2415        0        0        1        1        0  \n",
      "2416        0        0        1        1        0  \n",
      "\n",
      "[2417 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# le code ci-dessous recupère les données y dans un tableau numpy.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert the pandas DataFrame 'y' to a NumPy array.\n",
    "y_array = y.to_numpy()\n",
    "\n",
    "# Print the resulting NumPy array.\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Wsw8lQq5YCU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 51 78 ... 23  0 78]\n"
     ]
    }
   ],
   "source": [
    "y_unique, index_unique, reverse_unique = np.unique(y_array,return_index=True, return_inverse=True, axis=0)\n",
    "\n",
    "\n",
    "print(reverse_unique)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tableaux sont repectivement: les lignes uniques dans y array, l'index de ces ligne et le nombre de fois que chaque unique label apparait dans y array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKOLWJpNEKdf"
   },
   "source": [
    "Que contiennent les tableaux créés ci-dessus ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4va7_1KD_tJ"
   },
   "source": [
    "Construisez les données X_trainLS, X_testLS, y_trainLS, y_testLSpour la méthode Label Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WV5Hji_2EIbA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainLS shape: (1691, 103)\n",
      "X_testLS shape: (726, 103)\n",
      "y_trainLS shape: (1691,)\n",
      "y_testLS shape: (726,)\n"
     ]
    }
   ],
   "source": [
    "# Construct y_trainLS and y_testLS using reverse_unique\n",
    "y_trainLS = reverse_unique[:len(y_train)]\n",
    "y_testLS = reverse_unique[len(y_train):]\n",
    "\n",
    "# X_trainLS and X_testLS are the same as X_train and X_test\n",
    "X_trainLS = X_train\n",
    "X_testLS = X_test\n",
    "\n",
    "print(\"X_trainLS shape:\", X_trainLS.shape)\n",
    "print(\"X_testLS shape:\", X_testLS.shape)\n",
    "print(\"y_trainLS shape:\", y_trainLS.shape)\n",
    "print(\"y_testLS shape:\", y_testLS.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDnxtTvKeHwg"
   },
   "source": [
    "## Expériences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2989WYRJERv-"
   },
   "source": [
    "La fonction `reconstruit_y` ci-dessous reconstruit les prédictions du modèle appris avec la méthode Label Set au format attendu par les métriques de performance définies plus haut. Expliquez le fonctionnement de cette fonction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction va prendre en entrée les labels et les données y et va les transformer en un tableau de labels binaires ( ici 726 * 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3jwKaNuz2De-"
   },
   "outputs": [],
   "source": [
    "def reconstruit_y(yLS,  LS ): # reconstruit les vecteurs y (vecteurs d'indicateurs de labels yLS) à partir des LS (les labelsets)\n",
    "  y_temp = [LS[ yLS[i]] for i in range(len(yLS))]\n",
    "  y_temp = np.concatenate( y_temp, axis=0 )\n",
    "  y_temp = y_temp.reshape((yLS.shape[0],LS.shape[1]))\n",
    "  return y_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m48NJr1PEvHG"
   },
   "source": [
    "Faites quelques expériences avec la méthode Label Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxcivH9gE086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_testLS_reconstruit shape: (726, 14)\n",
      "y_testLS_reconstruit:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 1 0]\n",
      " ...\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 1 1 ... 1 1 0]]\n",
      "[[0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 1 0]\n",
      " ...\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 1 1 ... 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Test de la fonction reconstruit_y\n",
    "y_testLS_reconstruit = reconstruit_y(y_testLS, y_unique)\n",
    "print(\"y_testLS_reconstruit shape:\", y_testLS_reconstruit.shape)\n",
    "print(\"y_testLS_reconstruit:\")\n",
    "print(y_testLS_reconstruit)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8429752066115702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hamming Distance : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.239669421487603"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1 score : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.12128291974839289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Accuracy : ',get_accuracy_score(y_testLS_reconstruit ,y_pred), 'Hamming Distance : ', HammingDistance_score(y_testLS_reconstruit,y_pred) )\n",
    "display('F1 score : ',f1_score(y_testLS_reconstruit, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5JavgdyplMD"
   },
   "source": [
    "## Task 3: Implement the Classifier Chains Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmORXAgJFG1J"
   },
   "source": [
    "Cpmplétez la classe suivante qui implémente les classifier Chains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "mooZdGtUplMD"
   },
   "outputs": [],
   "source": [
    "class ClassifierChains(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, base_model=LogisticRegression(), order = None, undersample=False):\n",
    "        self.base_model = base_model # The base estimator\n",
    "        self.order = order # Order of labels in which the labels are to be sent to the classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_cpy = X.copy()\n",
    "        y_cpy = y.copy()\n",
    "        self.order_shuffle = None\n",
    "        if self.order is None:\n",
    "            self.order = list(range(y.shape[1]))\n",
    "            random.shuffle(self.order)\n",
    "        self.order_shuffle = self.order\n",
    "\n",
    "        self.model_list_ = []\n",
    "        for i in self.order_shuffle:\n",
    "            model = clone(self.base_model)\n",
    "            model.fit(X_cpy, y_cpy.iloc[:, i])\n",
    "            self.model_list_.append(model)\n",
    "            X_cpy = np.hstack((X_cpy, y_cpy.iloc[:, i].values.reshape(-1, 1)))\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_cpy = X.copy()\n",
    "        y_pred = np.zeros((X.shape[0], len(self.order_shuffle)))\n",
    "        for i, model in enumerate(self.model_list_):\n",
    "            y_pred[:, self.order_shuffle[i]] = model.predict(X_cpy)\n",
    "            X_cpy = np.hstack((X_cpy, y_pred[:, self.order_shuffle[i]].reshape(-1, 1)))\n",
    "        return pd.DataFrame(y_pred, columns=self.order_shuffle)\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "        #Not to be implemented\n",
    "\n",
    "        return None\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaVaXd9pE_PR"
   },
   "source": [
    "Faites des expériences avec la méthode Classifer Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "b6BdcKeeE-mk"
   },
   "outputs": [],
   "source": [
    "classchn = ClassifierChains(base_model=SVC(C=0.01, kernel='sigmoid', probability=True))\n",
    "classchn.fit(X_train,y_train)\n",
    "y_pred2 = classchn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8553719008264463"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hamming Distance : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.2355371900826446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1 score : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.12049772347410956"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Accuracy : ',get_accuracy_score(y_test,y_pred2), 'Hamming Distance : ', HammingDistance_score(y_test,y_pred2) )\n",
    "display('F1 score : ',f1_score(y_test, y_pred2, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsbrGsvxQtPk"
   },
   "source": [
    "# 2. Utilisation du package [scikit-multilearn](http://scikit.ml/modelselection.html)\n",
    "\n",
    "Installez ce package et utilisez le pour reproduire des expériences ci-dessus sur les mêmes données.\n",
    "\n",
    "Vosu ferez des expériences avec BR, Classifier Chain mais et des estimateurs de votre choix mais aussi avec de sméthodes naturellement transformées comme les KNN (MLKNN en version multilabel)\n",
    "\n",
    "A noter que le code du package se trouve [ici](https://github.com/scikit-multilearn/scikit-multilearn/tree/master/skmultilearn) et qu'un bug est idenfitié sur la méthode MLKNN à corriger selon [ces indications](https://stackoverflow.com/questions/74613688/typeerror-skmultilearn-error-with-multilabel-knn) en redéfinissant la classe MLKNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7_4opEmSBTv"
   },
   "source": [
    "Vous pourrez chercher les meileurs hyperparamètres avec un code tel que celui-ci pour le cas des MLKNNs.\n",
    "\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "parameters = {'k': range(1,20)}\n",
    "score = 'f1_weighted'\n",
    "\n",
    "classifier = GridSearchCV(MLkNN(), parameters, scoring=score)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "classifier.best_params_, classifier.best_score_\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7gtwTjuYR3l_"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskmultilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlknn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLkNN\n\u001b[0;32m      5\u001b[0m X_train, y_train, feature_names, label_names \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m X_test, y_test, _, _ \u001b[38;5;241m=\u001b[39mload_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "from .mlknn import MLkNN\n",
    "\n",
    "\n",
    "X_train, y_train, feature_names, label_names = load_dataset('emotions', 'train')\n",
    "X_test, y_test, _, _ =load_dataset('emotions', 'test')\n",
    "\n",
    "np.unique(y_train.rows).shape, np.unique(y_test.rows).shape\n",
    "\n",
    "\n",
    "classifier = MLkNN(k=3)\n",
    "prediction = classifier.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLkNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m20\u001b[39m)}\n\u001b[0;32m      2\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m classifier \u001b[38;5;241m=\u001b[39m GridSearchCV(\u001b[43mMLkNN\u001b[49m(), parameters, scoring\u001b[38;5;241m=\u001b[39mscore)\n\u001b[0;32m      5\u001b[0m classifier\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m      7\u001b[0m classifier\u001b[38;5;241m.\u001b[39mbest_params_, classifier\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MLkNN' is not defined"
     ]
    }
   ],
   "source": [
    "parameters = {'k': range(1,20)}\n",
    "score = 'f1_weighted'\n",
    "\n",
    "classifier = GridSearchCV(MLkNN(), parameters, scoring=score)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "classifier.best_params_, classifier.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "cdLjn4pEplL-"
   ],
   "provenance": [
    {
     "file_id": "1ORtrTAx5SjAqFyqANTrai-UYOsy6cnW-",
     "timestamp": 1733829331992
    },
    {
     "file_id": "1olnmtwMCtz4t72PEvHPxlhWY3bjzIxsL",
     "timestamp": 1733769929964
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
