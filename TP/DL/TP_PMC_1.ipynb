{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP 1 - DL \n",
    "Ce TP vise à implémenter en Numpy des parties d’un réseau de neurones ainsi que\n",
    "les fonctions d’entrainement et d’évaluation. Un squelette de code est disponible sur le\n",
    "Gitlab d’AMU : [Gitlab d’AMU](https://etulab.univ-amu.fr/ayache/nnn_etu). Lisez les instructions\n",
    "fournies dans le ReadMe pour comprendre l’architecture du code. Nous nous intéressons\n",
    "ici à l’implémentation de réseaux de neurones composés de couches denses mais l’extension\n",
    "à d’autres types de couches est tout à fait possible. Le jeu de données considéré est\n",
    "un sous-ensemble (10000 données d’entrainement) de MNIST (images \\(28 \\times 28\\) pixels\n",
    "vectorisées) pour une tâche de classification multiclasses : $\\mathbb{R}^{784} \\rightarrow \\mathbb{R}^{10}$.\n",
    "\n",
    "# Notations\n",
    "On considère les notations suivantes - similaires dans le code - pour un réseau dense à $L$\n",
    "couches. $a^{l-1}$ est un vecteur en entrée d’une couche $l$ ($a^0 := x$ est un vecteur d’entrée du\n",
    "réseau de neurones), $W^l$ est la matrice de poids et $b^l$ le vecteur de biais de la couche $l$\n",
    "(pour $l \\geq 1$).\n",
    "On note $a^l$ le vecteur de préactivations de la couche $l$ et $z^l$ le vecteur des valeurs (post-\n",
    "activations) en sortie de la fonction d’activation $g^l$. Les préactivations sont calculées\n",
    "suivant $a^l = z^{l-1} W^{l^T} + b^l$ et les postactivations par $z^l = g^l(a^l)$. On note $n^l$\n",
    "le nombre de neurones de la couche $l$. Le vecteur $a^l$ comme le vecteur $z^l$ sont donc des vecteurs dans\n",
    "$\\mathbb{R}^{n^l}$, on considère dans la suite que ce sont des vecteurs lignes. La matrice de poids de la\n",
    "couche $l$, $W^l$, est une matrice de dimensions : $W^l \\in \\mathbb{R}^{n^l \\times n^{l-1}}$.\n",
    "\n",
    "## I. Formalisation de la backpropagation pour un exemple d’apprentissage\n",
    "On utilise une fonction de coût $E$ qui renvoie le carré de la norme de la différence\n",
    "entre la sortie du réseau $z^L$ et le vecteur cible $y$ (MSE).\n",
    "On note $\\delta E = \\frac{\\partial E}{\\partial z^L}$ le gradient de la fonction de coût par rapport aux sorties du\n",
    "réseau.\n",
    "On note aussi $\\delta^L = \\frac{\\partial E}{\\partial a^L}$ le gradient de la fonction de coût par rapport aux activations\n",
    "(avant passage par la fonction d’activation) de la couche de sortie du réseau et $\\delta^l = \\frac{\\partial E}{\\partial a^l}$\n",
    "le gradient de la fonction de coût par rapport aux activations (avant passage par la\n",
    "fonction d’activation) de la couche intermédiaire numéro $l$.\n",
    "\n",
    "1. On s’intéresse à la couche de sortie du réseau de neurones. Dans le cas où\n",
    "    la fonction d’activation est appliquée composante par composante (comme une\n",
    "    sigmoide ou une ReLU) montrez que $\\delta^L := \\frac{\\partial E}{\\partial a^L} = \\delta E \\odot g'^L(a^L)$ où\n",
    "    $\\odot$ est le produit d’Hadamard, composante par composante.\n",
    "2. Démontrez que pour une couche intermédiaire $l + 1$, en considérant un neurone\n",
    "    de la couche $l + 1$, $i$, et un neurone de la couche $l$, $j$,\n",
    "    $\\frac{\\partial a^{l+1}[i]}{\\partial a^l[j]} = W^{l+1}[i, j]g'^l(a^l[j])$,\n",
    "    en notant $u[j]$ la $j$-ième composante d’un vecteur $u$. En déduire que $\\delta^l = [\\delta^{l+1} \\cdot W^{l+1}] \\odot g'^l(a^l)$, où $\\cdot$ est le produit matriciel.\n",
    "3. Démontrez que le gradient de l’erreur par rapport aux poids de la couche $l$ s’écrit\n",
    "    $\\delta^l \\cdot z^{T}_{l-1}$.\n",
    "4. Exprimez la règle de descente de gradient pour les poids de la couche $l$.\n",
    "\n",
    "\n",
    "## II. Extension de la formalisation au traitement d’un batch d’exemples\n",
    "On considère ici que l’on traite l’ensemble des données par batch.\n",
    "La fonction de coût E renvoie maintenant la moyenne sur un batch de l’écart entre\n",
    "la sortie du réseau $z_L$ et un vecteur cible y. Ainsi $z_L$ est maintenant une matrice de\n",
    "taille batch_size × $n_L$, al est une matrice de taille batch_size × $n_l$ etc.\n",
    "Revisitez l’ensemble des questions de l’exercice précédent en vérifiant si les formules\n",
    "sont toujours correctes ou en donnant des formules adaptées. Dans tous les cas\n",
    "précisez les dimensions des quantités manipulées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bausm\\OneDrive\\Documentos\\IAM\\TP\\DL\\NNN_v0\n"
     ]
    }
   ],
   "source": [
    "%cd \"c:\\Users\\bausm\\OneDrive\\Documentos\\IAM\\TP\\DL\\NNN_v0\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "\n",
      "--- Epoch: 1 ---\n",
      "\n",
      "Progress:\n",
      "Batch 800 / 833, accuracy: 0.00%, validation accuracy: 0.00%, mean execution time per batch: 0.15 ms\n",
      "\n",
      "--- Epoch: 2 ---\n",
      "\n",
      "Progress:\n",
      "Batch 800 / 833, accuracy: 0.00%, validation accuracy: 0.00%, mean execution time per batch: 0.15 ms\n",
      "\n",
      "--- Epoch: 3 ---\n",
      "\n",
      "Progress:\n",
      "Batch 800 / 833, accuracy: 0.00%, validation accuracy: 0.00%, mean execution time per batch: 0.15 ms\n",
      "\n",
      "--- Epoch: 4 ---\n",
      "\n",
      "Progress:\n",
      "Batch 800 / 833, accuracy: 0.00%, validation accuracy: 0.00%, mean execution time per batch: 0.15 ms\n",
      "\n",
      "--- Epoch: 5 ---\n",
      "\n",
      "Progress:\n",
      "Batch 800 / 833, accuracy: 0.00%, validation accuracy: 0.00%, mean execution time per batch: 0.16 ms\n",
      "\n",
      "--- Epoch: 6 ---\n",
      "\n",
      "Progress:\n",
      "Batch 800 / 833, accuracy: 0.00%, validation accuracy: 0.00%, mean execution time per batch: 0.15 ms\n",
      "\n",
      "--- Epoch: 7 ---\n",
      "\n",
      "Progress:\n",
      "Batch 800 / 833, accuracy: 0.00%, validation accuracy: 0.00%, mean execution time per batch: 0.16 ms\n",
      "\n",
      "--- Epoch: 8 ---\n",
      "\n",
      "Progress:\n",
      "Batch 800 / 833, accuracy: 0.00%, validation accuracy: 0.00%, mean execution time per batch: 0.15 ms\n",
      "\n",
      "--- Epoch: 9 ---\n",
      "\n",
      "Progress:\n",
      "Batch 800 / 833, accuracy: 0.00%, validation accuracy: 0.00%, mean execution time per batch: 0.15 ms\n",
      "\n",
      "--- Epoch: 10 ---\n",
      "\n",
      "Progress:\n",
      "Batch 800 / 833, accuracy: 0.00%, validation accuracy: 0.00%, mean execution time per batch: 0.15 ms\n",
      "\n",
      "Accuracy on test dataset: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i \"main.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Programmation de la boucle d’apprentissage du réseau de neurones\n",
    "\n",
    "Commencez par une lecture globale des différents fichiers pour comprendre l’architecture du code et l’enchainement des appels de fonctions. Cette partie se concentre sur le fichier 'neural_network.py'.\n",
    "\n",
    "1. La fonction fit est la fonction d’entrainement du réseau de neurones. A chaque\n",
    "epoch, l’ensemble du jeu d’entrainement est (rétro)propagé pour mettre à jour\n",
    "les paramètres du réseau. Complétez les parties manquantes de la fonction en\n",
    "suivant les étapes commentées dans le code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cost_functions import cost_functions\n",
    "from optimizers import optimizers\n",
    "from layers.dense import Dense\n",
    "from utils import generate_batches\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self,\n",
    "                 architecture=None,\n",
    "                 optimizer=\"sgd\",\n",
    "                 cost_function=\"mse\"\n",
    "                 ) -> None:\n",
    "\n",
    "        # ----- CLASSIFICATION ATTRIBUTES -----\n",
    "        self.layers: list = []\n",
    "        self.classes: dict = None\n",
    "\n",
    "        # ----- HYPER-PARAMETERS -----\n",
    "        self.batch_size: int = 32\n",
    "        self.number_of_epochs: int = 10\n",
    "        self.optimizer = optimizers[optimizer]()\n",
    "        self.cost_function = cost_functions[cost_function]()\n",
    "\n",
    "        self.initialize_architecture(architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self,\n",
    "              x: np.array,\n",
    "              y: np.array,\n",
    "              validation_data: np.array = None,\n",
    "              validation_data_labels: np.array = None,\n",
    "              learning_rate: float = None,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 50) -> None:\n",
    "        \"\"\"\n",
    "        This method trains the network. It takes an input vector and a label vector.\n",
    "        If no validation data is passed, the method keeps 10% of the training data to serve as validation data.\n",
    "\n",
    "        :param x: an array of input vectors\n",
    "        :param y: an array of label vectors\n",
    "        :param validation_data: an array of input vectors to measure the network validation accuracy throughout the\n",
    "        training session\n",
    "        :param validation_data_labels: an array of label vectors to measure the network validation accuracy throughout\n",
    "        the training session\n",
    "        :param learning_rate: a float used to define the learning rate of the optimizer\n",
    "        :param epochs: redefine the number of epochs for the network to be trained on\n",
    "        :param batch size: redefine the size of the batches use for training\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        # set class attributes\n",
    "        self.number_of_epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "        # sets the learning of the optimizer if passed as an argument\n",
    "        if learning_rate is not None:\n",
    "            self.optimizer.learning_rate = learning_rate\n",
    "        \n",
    "        # create batches iterator as a generator\n",
    "        batches = generate_batches(x, y, self.batch_size)\n",
    "        \n",
    "        ############                ############\n",
    "        ############ begin training ############\n",
    "        ############                ############\n",
    "        \n",
    "        # looping over epochs\n",
    "        for epoch in range(self.number_of_epochs):\n",
    "\n",
    "            print(f\"\\n--- Epoch: {epoch + 1} ---\\n\")\n",
    "            print(\"Progress:\")\n",
    "\n",
    "            timings = []\n",
    "\n",
    "            # looping over batches\n",
    "            for batch in range(x.shape[0] // self.batch_size):\n",
    "\n",
    "                start = perf_counter()\n",
    "\n",
    "                # get a random batch\n",
    "                x_batch, y_batch = next(batches)\n",
    "\n",
    "                # calculate output of the network for the given input\n",
    "                output = self.forward(x_batch)\n",
    "                # backpropagate the error through the whole network\n",
    "                self.backward(y_batch, output)\n",
    "                \n",
    "                # update the weights and biases of the network\n",
    "                self.update_parameters()\n",
    "                \n",
    "                timings.append(perf_counter() - start)\n",
    "\n",
    "                if batch % 100 == 0:\n",
    "                    # Monitoring training session\n",
    "                    print(f\"Batch {batch} / {x.shape[0] // self.batch_size}, \"\n",
    "                          f\"accuracy: {100 * self.evaluate(x, y):.2f}%, \"\n",
    "                          f\"validation accuracy: {100 * self.evaluate(validation_data, validation_data_labels):.2f}%, \"\n",
    "                          f\"mean execution time per batch: {1000 * np.mean(timings):.2f} ms\",\n",
    "                          end=\"\\r\")\n",
    "\n",
    "            print(\"\\n\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Complétez la fonction backpropagation en reprenant les formules rappelées plus\n",
    "haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(self, y: np.array, expected_output: np.array) -> None:\n",
    "    \"\"\"\n",
    "    This method computes the error that propagates through each layer of the network.\n",
    "\n",
    "    :param y: an array of size batch_size containing output vectors computed through inference an array of size batch_size containing output vectors computed through inference\n",
    "    :param expected_output: an array of size batch_size containing the desired output for each input vector\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # compute deltaE (TD notation)\n",
    "    deltaE = self.cost_function.derivative(y, expected_output)\n",
    "    # propagate the error from the last layer\n",
    "    delta_i = self.layers[-1].propagate_backward(deltaE)\n",
    "    # call recursive deltas from before last to first\n",
    "    for layer in self.layers[-2::-1]:\n",
    "        delta_i = layer.propagate_backward(delta_i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
