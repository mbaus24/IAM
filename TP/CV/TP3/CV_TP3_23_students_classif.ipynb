{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv4sGeDyHBWV"
      },
      "source": [
        "# Recognition - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dohW_X2KqWU"
      },
      "source": [
        "### Imports et installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBaSRtigHBok"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#!pip install -q keras\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-7NxP77K36R"
      },
      "source": [
        "### Mount your drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpf5mNPAo4K_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S1tiizHtRfq"
      },
      "outputs": [],
      "source": [
        "!ls\n",
        "print()\n",
        "!ls drive\n",
        "print()\n",
        "!ls drive/My\\ Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t06SWtvbJQMi"
      },
      "source": [
        "### Get the dataset\n",
        "\n",
        "Copy the dataset on your drive. Specify the path to your dataset in the following codes ! You could use !wget as an alternative.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rukULS6rFRhy"
      },
      "source": [
        "### List images from folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBgvPV9WFRh1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#import glob\n",
        "\n",
        "dir_path  = 'drive/MyDrive/PATH_TO_miniMIT'#####################################\n",
        "listDir = sorted(os.listdir(dir_path))#glob.glob(dir_path)\n",
        "print(listDir)\n",
        "\n",
        "for d in listDir:\n",
        "  #read subfolder\n",
        "  listFiles = sorted(os.listdir(dir_path+'/'+d))\n",
        "  print(listFiles)\n",
        "  print(len(listFiles))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b70OYifMFhE-"
      },
      "source": [
        "### Available networks\n",
        "\n",
        "We are going to use available pre-trained networks, see  https://keras.io/applications/\n",
        "\n",
        "We will first focus on VGG19.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqBnX63SFRh0"
      },
      "source": [
        "### Create one batch including all training images\n",
        "\n",
        "Note that images are preprocessed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l_EYooeFRh7"
      },
      "outputs": [],
      "source": [
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, ActivityRegularization, Lambda\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
        "from keras.layers import AveragePooling2D, Input\n",
        "######from keras.utils import np_utils\n",
        "from keras.utils import normalize\n",
        "from keras import backend as K\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "\n",
        "#import sklearn\n",
        "#from sklearn.preprocessing import normalize\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from keras.utils import load_img, img_to_array\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "dir_path  = 'drive/MyDrive/PATH_TO_miniMIT/train'##############################\"\"\n",
        "listDir = sorted(os.listdir(dir_path))\n",
        "print(len(listDir))\n",
        "\n",
        "\n",
        "\n",
        "X_train = np.zeros(shape=(40*3,224,224,3), dtype=np.float32)# train batch\n",
        "\n",
        "Y_train = np.zeros(shape=(40*3,3))\n",
        "Y_train[0:40,0]=1\n",
        "Y_train[40:80,1]=1\n",
        "Y_train[80:120,2]=1\n",
        "\n",
        "\n",
        "cpt = 0\n",
        "for d in listDir:#[listDir[1],  listDir[2] ,listDir[4]]:\n",
        "  #read subfolder\n",
        "  listFiles = sorted(os.listdir(dir_path+'/'+d))\n",
        "  print(d)\n",
        "  print(len(listFiles))\n",
        "\n",
        "  for f in listFiles:\n",
        "    img = load_img(dir_path+'/'+d+'/'+f, target_size=(224, 224))\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    #print(x.shape)\n",
        "    X_train[cpt,:,:,:] = x[0,:,:,:]\n",
        "    cpt+=1\n",
        "    print(cpt)\n",
        "\n",
        " #Use np.save(...) function if you want to save your train batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97qm85O5FRh7"
      },
      "source": [
        "### Build Similarly one batch for the test data X_test and its labels Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YN9MIrz0F1Y"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3WyfyYA0GYo"
      },
      "source": [
        "### Build a new network based on a pre-trained network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_4ChN0u1dCa"
      },
      "outputs": [],
      "source": [
        "network = VGG19(weights='imagenet')\n",
        "print(network.summary())\n",
        "\n",
        "network2 = Model(inputs=network.input, outputs=network.get_layer('block4_pool').output)#Use only the pre-trained convolutional layers\n",
        "#######You may also use network with the option include_top = False\n",
        "#print(network2.summary())\n",
        "network2.trainable = False# this freezes the layers of this network, i.e. the layers will not be updated\n",
        "print(network2.output_shape)\n",
        "\n",
        "\n",
        "#Building a new network to plug after the first one.\n",
        "input_shape = (14,14,512)\n",
        "\n",
        "x = Input(shape=input_shape, name='input')\n",
        "y0 = AveragePooling2D((14,14), padding='same')(x)# MaxPooling2D   AveragePooling2D ##### You may also use GlobalAveragePooling layers\n",
        "\n",
        "y0 = keras.layers.Normalization(axis=-1)(y0)\n",
        "y0 = Flatten()(y0)\n",
        "\n",
        "y0 = Dense(3)(y0)##\n",
        "y1 = Activation('softmax')(y0)\n",
        "\n",
        "model1 = Model(inputs=x,outputs=y1)\n",
        "\n",
        "#Combine the networks\n",
        "modelf = Model(inputs=network2.input, outputs=model1(network2.output))\n",
        "modelf.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "#print(modelf.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w77DWxcI_Xfq"
      },
      "source": [
        "### Train the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdPjcnHp9jV8"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "modelf.fit(X_train, Y_train, batch_size=40, epochs=50, verbose=1)\n",
        "#modelf.fit(X_train, Y_train, validation_data= (X_test,Y_test), batch_size=40, epochs=50, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t51gzG4y_baY"
      },
      "source": [
        "### Test the network on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imySyut_BABC"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoMLHu6oBAX-"
      },
      "source": [
        "### Play with the architecture\n",
        "\n",
        "> - Add 1 or 2 more fully connected layers (512 and 20 for exemple) with Relu and dropout ( https://keras.io/activations/ https://keras.io/layers/core/#dropout )\n",
        "\n",
        "> - Switch the optimizer to adam ( https://keras.io/optimizers/ ). What do you observe ? why ?\n",
        "\n",
        "> - Switch AveragePooling to MaxPooling\n",
        "\n",
        "> - Replace l2 normalization with Bath norm.\n",
        "\n",
        "> - Play with epochs and batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNll18ZNCUAb"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVQaRXqACaem"
      },
      "source": [
        "### Report the architectures tested and the performance obtained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2jWHWowCxe9"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmatk216CzGj"
      },
      "source": [
        "### Modify the network\n",
        "\n",
        "> - Extract the first (then second) fully connected layer from the pre-trained vgg19 (There is no need for pooling and flatenning)\n",
        "\n",
        "> - Compare your results to the convolutional layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP-5SXPWEprF"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwg4sSGsFGv4"
      },
      "source": [
        "### Use another network\n",
        "\n",
        "> - Choose another network, namely resnet, densenet, mobileNet, efficientNet...\n",
        "\n",
        "> - Study its architecture\n",
        "\n",
        "> - Similarly extract the final or penultimate convolutional layer, then add a couple of dense layers to perform classification. Compare performances with earlier networks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjxAkHKyFHBF"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myp3IhVBTL8j"
      },
      "source": [
        "### Play some more\n",
        "\n",
        "> - re-compute your batch with larger images as input (twice as large for instance). Then use a fully convolutional architecture such as ResNet or VGG with the option include_top= False. Add a global average (or max) pooling layer (if necessary), followed by a dense classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oalMglcATMfL"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emIIzrF_AFiy"
      },
      "source": [
        "##Optional\n",
        "\n",
        "You may build or get your own dataset and perform classification on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqJDnvDLAFwA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
